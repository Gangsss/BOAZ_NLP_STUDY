{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03.GloVe.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Gangsss/BOAZ_NLP_STUDY/blob/master/03_GloVe.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "w4AP1hGp3Jz7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. GloVe: Global Vectors for Word Representation"
      ]
    },
    {
      "metadata": {
        "id": "4O7xYjWdV2sr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "TmE0-l-U3Jz-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I recommend you take a look at these material first."
      ]
    },
    {
      "metadata": {
        "id": "9Y3Necki3J0A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* http://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture3.pdf\n",
        "* https://nlp.stanford.edu/pubs/glove.pdf"
      ]
    },
    {
      "metadata": {
        "id": "CIGe992z3QxB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQ0o-j8B3J0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "random.seed(1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bCsOGbNi3J0J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4294610d-3f61-45b4-8d6e-24fcf8f32ccc"
      },
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(nltk.__version__)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3.0.post4\n",
            "3.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rMNH5-7P3J0W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "gpus = [0]\n",
        "torch.cuda.set_device(gpus[0])\n",
        "\n",
        "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
        "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpqK8ngz3J0b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getBatch(batch_size, train_data):\n",
        "    random.shuffle(train_data)\n",
        "    sindex = 0\n",
        "    eindex = batch_size\n",
        "    while eindex < len(train_data):\n",
        "        batch = train_data[sindex:eindex]\n",
        "        temp = eindex\n",
        "        eindex = eindex + batch_size\n",
        "        sindex = temp\n",
        "        yield batch\n",
        "    \n",
        "    if eindex >= len(train_data):\n",
        "        batch = train_data[sindex:]\n",
        "        yield batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7e0i_tok3J0g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return Variable(LongTensor(idxs))\n",
        "\n",
        "def prepare_word(word, word2index):\n",
        "    return Variable(LongTensor([word2index[word]]) if word2index.get(word) is not None else LongTensor([word2index[\"<UNK>\"]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NaBDvvu53J0n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data load and Preprocessing "
      ]
    },
    {
      "metadata": {
        "id": "daLC-E0c3J0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6515ddb3-a490-46b0-ed79-6eb894a37640"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "\n",
        "corpus = list(nltk.corpus.gutenberg.sents('melville-moby_dick.txt'))[:500]\n",
        "# 대문자 -> 소문자 처리\n",
        "corpus = [[word.lower() for word in sent] for sent in corpus]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cVHkiq4S3J0v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build vocab"
      ]
    },
    {
      "metadata": {
        "id": "RVqeS6NO3J0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d22015e-b0e7-41c2-96ff-a86976032675"
      },
      "cell_type": "code",
      "source": [
        "vocab = list(set(flatten(corpus)))\n",
        "print(vocab[0:5])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['10', 'fates', '1690', 'boots', 'though']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "idTr8RuO3J03",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2index = {}\n",
        "# word2index - word : index 형태\n",
        "for vo in vocab:\n",
        "    if word2index.get(vo) is None:\n",
        "        word2index[vo] = len(word2index)\n",
        "        \n",
        "# index2word - index : word 형태로 변경\n",
        "index2word={v:k for k, v in word2index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kYiagk_F3J09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccf1a675-b4b6-495f-845b-928e462b306c"
      },
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 5\n",
        "windows =  flatten([list(nltk.ngrams(['<DUMMY>'] * WINDOW_SIZE + c + ['<DUMMY>'] * WINDOW_SIZE, WINDOW_SIZE * 2 + 1)) for c in corpus])\n",
        "print(windows[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('<DUMMY>', '<DUMMY>', '<DUMMY>', '<DUMMY>', '<DUMMY>', '[', 'moby', 'dick', 'by', 'herman', 'melville')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vftp32F4bEMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64789ace-e228-4ea5-a8cc-7f3eb9fff1f6"
      },
      "cell_type": "code",
      "source": [
        "window_data = []\n",
        "\n",
        "for window in windows:\n",
        "    for i in range(WINDOW_SIZE * 2 + 1):\n",
        "        if i == WINDOW_SIZE or window[i] == '<DUMMY>': \n",
        "            continue\n",
        "        window_data.append((window[WINDOW_SIZE], window[i]))\n",
        "\n",
        "print(window_data[0:5])\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('[', 'moby'), ('[', 'dick'), ('[', 'by'), ('[', 'herman'), ('[', 'melville')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ui_qq7E03J1H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Weighting Function "
      ]
    },
    {
      "metadata": {
        "id": "gIA3nr6U3J1J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"../images/03.glove-weighting-function.png\">\n",
        "<center>borrowed image from https://nlp.stanford.edu/pubs/glove.pdf</center>"
      ]
    },
    {
      "metadata": {
        "id": "j6cbYFgq3J1K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weighting(w_i, w_j):\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "    except:\n",
        "        x_ij = 1\n",
        "        \n",
        "    x_max = 100 #100 # fixed in paper\n",
        "    alpha = 0.75\n",
        "    \n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij/x_max)**alpha\n",
        "    else:\n",
        "        result = 1\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r4vjg-Zz3J1S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build Co-occurence Matrix X"
      ]
    },
    {
      "metadata": {
        "id": "cWM-3xnu3J1U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because of model complexity, It is important to determine whether a tighter bound can be placed on the number of nonzero elements of X."
      ]
    },
    {
      "metadata": {
        "id": "y4C7IQYp3J1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_i = Counter(flatten(corpus)) # X_i\n",
        "#각 단어의 count 수"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3RlvC-m93J1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "730dcaa3-318b-47b0-9f2b-14cee44d4508"
      },
      "cell_type": "code",
      "source": [
        "X_ik_window_5 = Counter(window_data) # Co-occurece in window size 5\n",
        "# 같이 등장한 쌍들의 갯수 \n",
        "print(list(X_ik_window_5)[0:5])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('[', 'moby'), ('[', 'dick'), ('[', 'by'), ('[', 'herman'), ('[', 'melville')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1zmr-DjM345l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print(X_ik_window_5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RMuunvdm2vWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "068e277f-a7d0-4c7b-bfee-61251c1f14b3"
      },
      "cell_type": "code",
      "source": [
        "X_ik_window_5[('.', '.')]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "XM1VQ4PE3J1f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_ik = {}\n",
        "weighting_dic = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rB-HPhAC3J1i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from itertools import combinations_with_replacement\n",
        "#combinations_with_replacement('ABCD', 2) ->\t \tAA AB AC AD BB BC BD CC CD DD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEDCoA7Pcqno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7ed6e07f-2cc6-458f-b75f-c59bffbd487f"
      },
      "cell_type": "code",
      "source": [
        "vocab_c= list(combinations_with_replacement(vocab, 2))\n",
        "print(vocab_c[0:10])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('10', '10'), ('10', 'fates'), ('10', '1690'), ('10', 'boots'), ('10', 'though'), ('10', 'whatsoever'), ('10', 'cheever'), ('10', 'separate'), ('10', 'fireplaces'), ('10', 'objectionable')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-OrERa-Q5uUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weighting(w_i, w_j):\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "    except:\n",
        "        x_ij = 1\n",
        "        \n",
        "    x_max = 100 #100 # fixed in paper\n",
        "    alpha = 0.75\n",
        "    \n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij/x_max)**alpha\n",
        "    else:\n",
        "        result = 1\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQZX55oq3J1k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for bigram in combinations_with_replacement(vocab, 2): \n",
        "    if X_ik_window_5.get(bigram) is not None: # nonzero elements\n",
        "        co_occer = X_ik_window_5[bigram] #\n",
        "        X_ik[bigram] = co_occer + 1 # log(Xik) -> log(Xik+1) to prevent divergence(발산)\n",
        "        X_ik[(bigram[1],bigram[0])] = co_occer+1\n",
        "    else:\n",
        "        pass\n",
        "        \n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1])\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KnOK9acx3tGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38e4452d-2ab3-40be-f1a2-4a7cd4375391"
      },
      "cell_type": "code",
      "source": [
        "X_ik[('10', 'or')]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "sYRC3hyB4ceB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b98c4d85-b0af-4c0e-b851-27890ddc37de"
      },
      "cell_type": "code",
      "source": [
        "print(weighting_dic['10', 'or'])\n",
        "print(weighting_dic['or', '10'])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.053182958969449884\n",
            "0.053182958969449884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JVHrKG7y3J1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4b447f88-9e88-4ba3-d3b6-873db31d9d67"
      },
      "cell_type": "code",
      "source": [
        "test = random.choice(window_data)\n",
        "print(test)\n",
        "try:\n",
        "    print(X_ik[(test[0], test[1])] == X_ik[(test[1], test[0])])\n",
        "except:\n",
        "    1"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('sacred', 'any')\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IMMukdRY3J1t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare train data"
      ]
    },
    {
      "metadata": {
        "id": "G6rkf5Lr3J1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "f56447b4-2a65-4dca-958e-6b383d6857ab"
      },
      "cell_type": "code",
      "source": [
        "u_p = [] # center vec\n",
        "v_p = [] # context vec\n",
        "co_p = [] # log(x_ij)\n",
        "weight_p = [] # f(x_ij)\n",
        "\n",
        "for pair in window_data: \n",
        "    u_p.append(prepare_word(pair[0], word2index).view(1, -1))\n",
        "    v_p.append(prepare_word(pair[1], word2index).view(1, -1))\n",
        "    \n",
        "    try:\n",
        "        cooc = X_ik[pair]\n",
        "    except:\n",
        "        cooc = 1\n",
        "\n",
        "    co_p.append(torch.log(Variable(FloatTensor([cooc]))).view(1, -1))\n",
        "    weight_p.append(Variable(FloatTensor([weighting_dic[pair]])).view(1, -1))\n",
        "                                  \n",
        "train_data = list(zip(u_p, v_p, co_p, weight_p))\n",
        "del u_p\n",
        "del v_p\n",
        "del co_p\n",
        "del weight_p\n",
        "print(train_data[0]) # tuple (center vec i, context vec j log(x_ij), weight f(w_ij))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Variable containing:\n",
            " 1059\n",
            "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
            ", Variable containing:\n",
            " 240\n",
            "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
            ", Variable containing:\n",
            " 0.6931\n",
            "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
            ", Variable containing:\n",
            "1.00000e-02 *\n",
            "  5.3183\n",
            "[torch.cuda.FloatTensor of size 1x1 (GPU 0)]\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "67pKLm_c3J1y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modeling "
      ]
    },
    {
      "metadata": {
        "id": "eOsa7h2h3J1z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"../images/03.glove-objective.png\">\n",
        "<center>borrowed image from https://nlp.stanford.edu/pubs/glove.pdf</center>"
      ]
    },
    {
      "metadata": {
        "id": "m0gLEJBr3J10",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GloVe(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size,projection_dim):\n",
        "        super(GloVe,self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, projection_dim) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, projection_dim) # out embedding\n",
        "        \n",
        "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
        "        \n",
        "        initrange = (2.0 / (vocab_size + projection_dim))**0.5 # Xavier init\n",
        "        self.embedding_v.weight.data.uniform_(-initrange, initrange) # init\n",
        "        self.embedding_u.weight.data.uniform_(-initrange, initrange) # init\n",
        "        self.v_bias.weight.data.uniform_(-initrange, initrange) # init\n",
        "        self.u_bias.weight.data.uniform_(-initrange, initrange) # init\n",
        "        \n",
        "    def forward(self, center_words, target_words, coocs, weights):\n",
        "        center_embeds = self.embedding_v(center_words) # B x 1 x D\n",
        "        target_embeds = self.embedding_u(target_words) # B x 1 x D\n",
        "        \n",
        "        center_bias = self.v_bias(center_words).squeeze(1) \n",
        "        target_bias = self.u_bias(target_words).squeeze(1) \n",
        "        \n",
        "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2) \n",
        "        # Bx1xD * BxDx1 => Bx1x1 => Bx1\n",
        "        \n",
        "        loss = weights*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
        "        \n",
        "        return torch.sum(loss)\n",
        "    \n",
        "    def prediction(self, inputs):\n",
        "        v_embeds = self.embedding_v(inputs) # B x 1 x D\n",
        "        u_embeds = self.embedding_u(inputs) # B x 1 x D\n",
        "                \n",
        "        return v_embeds+u_embeds # final embed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItAUKNww3J12",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train "
      ]
    },
    {
      "metadata": {
        "id": "-IA3EUkd3J13",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 50\n",
        "BATCH_SIZE = 256\n",
        "EPOCH = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZdhNCji3J17",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "model = GloVe(len(word2index), EMBEDDING_SIZE)\n",
        "if USE_CUDA:\n",
        "    model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V1W_5GQn3J2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ab651bb7-9bf3-4aaa-a257-9cfd066fe79b"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCH):\n",
        "    for i,batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
        "        \n",
        "        inputs, targets, coocs, weights = zip(*batch)\n",
        "        \n",
        "        inputs = torch.cat(inputs) # B x 1\n",
        "        targets = torch.cat(targets) # B x 1\n",
        "        coocs = torch.cat(coocs)\n",
        "        weights = torch.cat(weights)\n",
        "        model.zero_grad()\n",
        "\n",
        "        loss = model(inputs, targets, coocs, weights)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        losses.append(loss.data.tolist()[0])\n",
        "    if epoch % 10 == 0:\n",
        "        print(\"Epoch : %d, mean_loss : %.02f\" % (epoch, np.mean(losses)))\n",
        "        losses = []"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0, mean_loss : 217.72\n",
            "Epoch : 10, mean_loss : 2.74\n",
            "Epoch : 20, mean_loss : 0.56\n",
            "Epoch : 30, mean_loss : 0.13\n",
            "Epoch : 40, mean_loss : 0.05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YuQz2i9w3J2H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test "
      ]
    },
    {
      "metadata": {
        "id": "zkyqzsjW3J2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word_similarity(target, vocab):\n",
        "    if USE_CUDA:\n",
        "        target_V = model.prediction(prepare_word(target, word2index))\n",
        "    else:\n",
        "        target_V = model.prediction(prepare_word(target, word2index))\n",
        "    similarities = []\n",
        "    for i in range(len(vocab)):\n",
        "        if vocab[i] == target: \n",
        "            continue\n",
        "        \n",
        "        if USE_CUDA:\n",
        "            vector = model.prediction(prepare_word(list(vocab)[i], word2index))\n",
        "        else:\n",
        "            vector = model.prediction(prepare_word(list(vocab)[i], word2index))\n",
        "        \n",
        "        cosine_sim = F.cosine_similarity(target_V, vector).data.tolist()[0] \n",
        "        similarities.append([vocab[i], cosine_sim])\n",
        "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KC6QOvQd3J2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "258fb477-2d53-4340-f8fd-3a130717944d"
      },
      "cell_type": "code",
      "source": [
        "test = random.choice(list(vocab))\n",
        "test"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'unwieldy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "sfL0zUSm3J2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "8deb610d-0693-4afe-85f7-ea8cac895328"
      },
      "cell_type": "code",
      "source": [
        "word_similarity(test, vocab)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['joy', 0.9673048853874207],\n",
              " ['express', 0.9609348773956299],\n",
              " ['sailors', 0.7666824460029602],\n",
              " ['icelandic', 0.722845733165741],\n",
              " ['exercise', 0.720321536064148],\n",
              " ['virtue', 0.7200307846069336],\n",
              " ['gloom', 0.7103403210639954],\n",
              " ['breedeth', 0.6963592767715454],\n",
              " ['competent', 0.6893061399459839],\n",
              " ['judgmatically', 0.6890193819999695]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "n5xlvpNj3J2Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TODO"
      ]
    },
    {
      "metadata": {
        "id": "bz4TMleZ3J2b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Use <a href=\"https://docs.scipy.org/doc/scipy/reference/sparse.html\">sparse-matrix</a> to build co-occurence matrix for memory efficiency"
      ]
    },
    {
      "metadata": {
        "id": "qZe4kBvZ3J2c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Suggested Readings"
      ]
    },
    {
      "metadata": {
        "id": "Eja5k0wk3J2e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* <a href=\"http://ruder.io/word-embeddings-2017/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=The%20Wild%20Week%20in%20AI\">Word embeddings in 2017: Trends and future directions</a>"
      ]
    }
  ]
}